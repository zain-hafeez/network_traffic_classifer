# -*- coding: utf-8 -*-
"""grdio_interface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LI8MAbydv4krdRzALjNSbrE5MRnbD_68
"""

## mounting google drive
from google.colab import drive
drive.mount('/content/drive')

!pip install gradio

import numpy as np
import pandas as pd
import tensorflow as tf
import gradio as gr

# Load the saved model
model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/network_traffic_classifier.keras')

# Define the attack dictionary
attack_dict = {
    'normal': 'normal',
    'DoS': 'DoS',
    'Probe': 'Probe',
    'R2L': 'R2L',
    'U2R': 'U2R'
}

# Define the preprocessing function
def preprocess_data(df):
    required_columns = ['protocol_type', 'service', 'flag'] + [f'feature_{i}' for i in range(1, 34)]  # Assuming 36 features

    # Ensure the dataframe has the correct columns
    if len(df.columns) != len(required_columns):
        raise ValueError(f"Expected {len(required_columns)} columns, but got {len(df.columns)}.")

    # Convert categorical columns to numeric using Label Encoding
    df['protocol_type'] = df['protocol_type'].astype('category').cat.codes
    df['service'] = df['service'].astype('category').cat.codes
    df['flag'] = df['flag'].astype('category').cat.codes

    # Standardize the feature columns
    df.iloc[:, :-1] = (df.iloc[:, :-1] - df.iloc[:, :-1].mean()) / df.iloc[:, :-1].std()

    return df

# Function to map predictions to attack classes
def map_predictions(predictions):
    # Ensure the number of unique classes in predictions matches the attack_dict
    inverse_attack_dict = {i: v for i, v in enumerate(attack_dict.values())}

    # Fallback for classes not found in dictionary
    mapped_preds = [inverse_attack_dict.get(pred, "Unknown") for pred in predictions]

    return mapped_preds

# Function to make predictions from the uploaded file
def predict_from_file(file):
    # Read the uploaded CSV file
    df = pd.read_csv(file.name)  # Access the file content with .name

    # Preprocess the data
    df_preprocessed = preprocess_data(df)

    # Make predictions
    predictions = model.predict(df_preprocessed)
    predicted_classes = np.argmax(predictions, axis=1)

    # Debugging: print predicted classes and ensure they match the attack dictionary
    print("Predicted classes:", predicted_classes)

    # Map predictions back to attack categories
    final_predictions = map_predictions(predicted_classes)

    # Return predictions as a single string
    return ', '.join(final_predictions)

# Create the Gradio interface
iface = gr.Interface(
    fn=predict_from_file,
    inputs=gr.File(label="Upload CSV File"),  # Use gr.File instead of gr.inputs.File
    outputs=gr.Textbox(label="Predictions"),   # Use gr.Textbox to handle multiple predictions
    live=False
)

# Launch the interface
iface.launch(debug=True)

