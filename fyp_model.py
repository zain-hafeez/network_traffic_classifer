# -*- coding: utf-8 -*-
"""fyp_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14TTBzjjn8Ek6Jdg9lowTGVlsm3k1VhbT
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

### coonecting  google drive
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/KDDTrain.csv')

df.head()

### droping classnum column
df7 = df.drop('classnum', axis=1)
df7.head()

df7.info()

df.columns.c

df7['class'].value_counts()

df7['class'].unique()

df7.isnull().sum()

# Provided attack_dict
attack_dict = {
    'normal': 'normal',

    'back': 'DoS',
    'land': 'DoS',
    'neptune': 'DoS',
    'pod': 'DoS',
    'smurf': 'DoS',
    'teardrop': 'DoS',
    'mailbomb': 'DoS',
    'apache2': 'DoS',
    'processtable': 'DoS',
    'udpstorm': 'DoS',

    'ipsweep': 'Probe',
    'nmap': 'Probe',
    'portsweep': 'Probe',
    'satan': 'Probe',
    'mscan': 'Probe',
    'saint': 'Probe',

    'ftp_write': 'R2L',
    'guess_passwd': 'R2L',
    'imap': 'R2L',
    'multihop': 'R2L',
    'phf': 'R2L',
    'spy': 'R2L',
    'warezclient': 'R2L',
    'warezmaster': 'R2L',
    'sendmail': 'R2L',
    'named': 'R2L',
    'snmpgetattack': 'R2L',
    'snmpguess': 'R2L',
    'xlock': 'R2L',
    'xsnoop': 'R2L',
    'worm': 'R2L',

    'buffer_overflow': 'U2R',
    'loadmodule': 'U2R',
    'perl': 'U2R',
    'rootkit': 'U2R',
    'httptunnel': 'U2R',
    'ps': 'U2R',
    'sqlattack': 'U2R',
    'xterm': 'U2R'
}



### comparing keys of attack_dictionary with class column
class_unique = df7['class'].unique()
for i in class_unique:
  if i not in attack_dict.keys():
    print(i)

### maping class column with attack dictionary
df7['class'] = df7['class'].map(attack_dict)
df7.head()

df7['class'].isna().sum()

df7['class'].nunique()

df7['class'].value_counts()

df7['class'].tail(1)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Encoding 'protocol_type', 'service', 'flag' using LabelEncoder
label_encoders = {}
for col in ['protocol_type', 'service', 'flag']:
    le = LabelEncoder()
    df7[col] = le.fit_transform(df7[col])
    label_encoders[col] = le

# Encoding 'class' using LabelEncoder
le_class = LabelEncoder()
df7['class'] = le_class.fit_transform(df7['class'])

df7.head()

print(df7['protocol_type'].unique())
print(df7['service'].unique())
print(df7['flag'].unique())
print(df7['class'].unique())

# Standardize features by removing the mean and scaling to unit variance
scaler = StandardScaler()
df7.iloc[:, :-1] = scaler.fit_transform(df7.iloc[:, :-1])

# Split the data into train and test sets
X = df7.drop(columns=['class'])
y = df7['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# One-hot encode the target variable
y_train_encoded = to_categorical(y_train, num_classes=5)
y_test_encoded = to_categorical(y_test, num_classes=5)

# Build the model
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(5, activation='softmax')  # Adjusted output layer for 5 classes
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test, y_test_encoded))

loss, accuracy = model.evaluate(X_test, y_test_encoded)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

model.save('/content/drive/MyDrive/Colab Notebooks/network_traffic_classifier.h5')



model.save('/content/drive/MyDrive/Colab Notebooks/network_traffic_classifier.keras')

df7.head()

